# fraud-detection-logistic-vs-tree-vs-perceptron
Colegio de Matem√°ticas Bourbaki - WA2503 - Machine Learning &amp; AI for the Working Analyst - Examen Modulo I -  Proyecto de aprendizaje supervisado para detecci√≥n de fraude. Incluye EDA, preparaci√≥n de datos y comparaci√≥n de modelos (Perceptr√≥n, √Årbol de Decisi√≥n y Regresi√≥n Log√≠stica) aplicados al dataset FraudeCanastas.csv.

# üß† Pr√°ctica Integrada de Clasificaci√≥n ‚Äî Detecci√≥n de Fraude

Este repositorio contiene la pr√°ctica final del m√≥dulo de **Aprendizaje Supervisado (Clases 1‚Äì13)**, 
centrada en la construcci√≥n, entrenamiento y evaluaci√≥n de modelos de clasificaci√≥n binaria 
para identificar posibles fraudes en transacciones financieras.

---

## üéØ Objetivo del proyecto
Desarrollar un modelo de **Machine Learning supervisado** que prediga si una transacci√≥n es fraudulenta (1) o no (0), 
siguiendo el flujo completo del proceso de modelado:

1. **Lectura del dataset**
2. **Exploraci√≥n de datos (EDA)**
3. **Preparaci√≥n y limpieza de datos**
4. **Elecci√≥n del modelo**
5. **Entrenamiento y prueba**
6. **Evaluaci√≥n de resultados**

---

## üß© Dataset
**Fuente:** `FraudeCanastas.csv`  
Contiene informaci√≥n sobre compras financiadas y una variable objetivo `fraud_flag` 
que indica si la operaci√≥n fue fraudulenta (1) o leg√≠tima (0).

- **Registros:** 115,988  
- **Variables:** 147  
- **Tasa de fraude:** ~1.4%

---

## ‚öôÔ∏è Modelos evaluados
| Modelo | Concepto | Tipo |
|:--|:--|:--|
| **Perceptr√≥n** | Clasificador lineal basado en hiperplano | Lineal |
| **√Årbol de Decisi√≥n (ID3)** | Divisi√≥n por ganancia de informaci√≥n (entrop√≠a) | No lineal |
| **Regresi√≥n Log√≠stica** | Clasificaci√≥n probabil√≠stica mediante funci√≥n sigmoide | Lineal |

---

## üìä Resultados principales
| Modelo | Precision (clase 1) | Recall (clase 1) | F1-score (clase 1) | Accuracy |
|:--|:--|:--|:--|:--|
| **Regresi√≥n Log√≠stica** | 0.33 | 0.75 | 0.46 | **0.75** |
| **Perceptr√≥n** | 0.26 | 0.82 | 0.39 | 0.64 |
| **√Årbol de Decisi√≥n** | 0.27 | 0.72 | 0.39 | 0.69 |

**Conclusi√≥n:**  
La **Regresi√≥n Log√≠stica** fue el modelo con mejor equilibrio entre *precision* y *recall*, 
adem√°s de ofrecer interpretabilidad y capacidad probabil√≠stica para ajustar umbrales de decisi√≥n.

---

## üßæ Conclusiones generales
- Los tres modelos logran detectar fraudes, pero la **Regresi√≥n Log√≠stica** se muestra m√°s estable y generalizable.  
- El **Perceptr√≥n** prioriza recall (detecta m√°s fraudes, pero con muchos falsos positivos).  
- El **√Årbol de Decisi√≥n** es √∫til para interpretaci√≥n, pero tiende a sobreajustar.  
- El pipeline propuesto puede ampliarse con t√©cnicas de **regularizaci√≥n**, **tuning** o **ensembles (Random Forest, XGBoost)**.

---

## üß∞ Librer√≠as utilizadas
- pandas, numpy  
- matplotlib, seaborn  
- scikit-learn  

---

## üìÇ Estructura del repositorio
